---
author: Michael Kaminsky
title: "Agile Analytics, Part 3: The Adjustments"
publishDate: "2018-07-01"
draft: true
tags: 
 - agile
 - scrum
 - process
---


Agile software engineering practices have become the standard work management tool for modern software development teams. Are these techniques applicable to analytics, or is the nature of research prohibitively distinct from the nature of engineering?

In this post I discuss some adjustments to the scrum methodology to make the process work better for analytics and data science teams.

<!--more-->

If you haven't already read them, you can find

* [part 1 here]({{< relref "agile-analytics-p1.md" >}})
* [part 2 here]({{< relref "agile-analytics-p1.md" >}})

When managing a team of analysts and data scientists, we want to leverage [all of the best things]({{< relref "agile-analytics-p1.md" >}}) about the scrum methodology while adjusting for [the things that don't work so well]({{< relref "agile-analytics-p1.md" >}}). The general theme of this post is how to carve out some room in scrum for exploration, research, and iterative problem definition.

# Key Adjustments to Scrum for Analytics

  * Time-bound spikes for research
  * Built in slack time for exploration
  * Acceptance Criteria includes “write the next story” 
  * Peer-review instead of sprint-review


## Time-bound spikes for research

In order to address the difficulties in using scrum for research and exploratory data analysis, I recommend leveraging the notion of a time-bound "spike" on a particular subject. Here are a few examples of spikes you could pursue:

* Research the state-of-the-art in LTV modeling for e-commerce companies. 
* Do retention rates even vary by acquisition channel or geography? (Is this worth pursuing further?)   
* What would it take to get an MVP  recommender system working on our website? Sketch the architecture and evaluate potential upside.

All of these are interesting technical questions that require a data scientist or analyst to answer, but 1) it's unclear exactly what the right path to completing the task is, and 2) you can imagine spending nearly infinite amounts of time on each of these questions if you let yourself bury into the rabbit-hole
 
To address these issues, you should treat these as time-bounded tasks. For example, you might say that the deliverable is a one-page document outlining the results of the investigation, and you shouldn't spend more than two working days on the task (or whatever is appropriate.) 

If the task seems like it's going to take longer, that's a good time for the analyst or data scientist to come up for air and discuss what they've found with the group before pursuing the task any further.

## Built in slack time for exploration



## ACs to "write the next story"


## Peer-review in show-and-tell




# Conclusion

